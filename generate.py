import os
import re
from openai import OpenAI
import azure.cognitiveservices.speech as speechsdk
import genanki

def generate_word_card(input_text: str, api_config: dict = None) -> dict:
    """
    è¾“å…¥ä¸€ä¸ªå•è¯æˆ–è¯ç»„ï¼ˆå¯èƒ½åŒ…å«ä¸Šä¸‹æ–‡æ‹¬å·ï¼‰ï¼Œé€šè¿‡ API è°ƒç”¨ç”ŸæˆéŸ³æ ‡ã€é‡Šä¹‰å’Œä¾‹å¥ã€‚
    
    Args:
        input_text (str): ç”¨æˆ·è¾“å…¥çš„å•è¯ï¼Œä¾‹å¦‚ "tear (crying)" æˆ– "bank"
        api_config (dict, optional): API é…ç½®å­—å…¸ï¼ŒåŒ…å« base_url, api_key, model_name
        
    Returns:
        dict: åŒ…å«æ¸…æ´—åçš„å•è¯ã€éŸ³æ ‡ã€é‡Šä¹‰åˆ—è¡¨å­—ç¬¦ä¸²ã€ä¾‹å¥åˆ—è¡¨å­—ç¬¦ä¸²
    """
    
    # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯ (ä½¿ç”¨é…ç½®æˆ–é»˜è®¤å€¼)
    if api_config is None:
        api_config = {
            "base_url": "https://ark.cn-beijing.volces.com/api/v3",
            "api_key": "è¯·åœ¨ config.yaml ä¸­é…ç½®ä½ çš„ API Key",
            "model_name": "deepseek-v3-2-251201"
        }
    
    client = OpenAI(
        base_url=api_config.get("base_url", "https://ark.cn-beijing.volces.com/api/v3"),
        api_key=api_config.get("api_key", ""),
    )
    
    # æ¨¡å‹åç§°
    MODEL_NAME = api_config.get("model_name", "deepseek-v3-2-251201")

    # 2. è¾…åŠ©å‡½æ•°ï¼šå¤„ç†æ‹¬å·ï¼Œè·å–çº¯å•è¯
    # æ­£åˆ™åŒ¹é…ä¸­æ–‡æ‹¬å· ï¼ˆï¼‰ æˆ–è‹±æ–‡æ‹¬å· () åŠå…¶å†…éƒ¨å†…å®¹ï¼Œå¹¶å»é™¤
    cleaned_word = re.sub(r'[\(\uff08].*?[\)\uff09]', '', input_text).strip()

    # 3. è¾…åŠ©å‡½æ•°ï¼šé€šç”¨ API è°ƒç”¨
    def get_completion(system_prompt, user_content):
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content},
                ],
                temperature=0.1, # é™ä½éšæœºæ€§ï¼Œä¿è¯è¾“å‡ºæ ¼å¼ç¨³å®š
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"APIè°ƒç”¨å‡ºé”™: {e}")
            return "Error generating content"

    # ==========================================
    # æ­¥éª¤ 1: è·å–éŸ³æ ‡ (IPA)
    # ==========================================
    ipa_prompt = """
You are an expert phonetician specializing in British English pronunciation.
Your task is to provide the International Phonetic Alphabet (IPA) transcription for the input text.

**Rules:**
1.  **Input format:** The input may be a single word, a phrase/idiom, or a word/phrase followed by a context in parentheses.
2.  **Phrases:** If the input is a phrase (e.g., "give up"), provide the IPA for each word in the phrase, separated by spaces.
3.  **Context:** If parentheses are present, use them to determine pronunciation (e.g., tear), but DO NOT transcribe the content inside parentheses.
4.  **Constraints:** Output ONLY the IPA symbols. No labels, no explanations.

**Examples:**

Input: apple
Output: /ËˆÃ¦pl/

Input: look forward to
Output: /lÊŠk ËˆfÉ”ËwÉ™d tu/

Input: a piece of cake
Output: /É™ piËs É™v keÉªk/

Input: tear (crying)
Output: /tÉªÉ™/

Input: tear (rip paper)
Output: /teÉ™/

Input: present (gift)
Output: /Ëˆpreznt/
"""
    # æ³¨æ„ï¼šPrompts é‡Œçš„ {{INPUT}} åœ¨è¿™é‡Œé€šè¿‡ user message ä¼ é€’ï¼Œæˆ–è€…ç›´æ¥ f-string æ›¿æ¢
    # è¿™é‡Œæˆ‘ä»¬é€‰æ‹©å°† system prompt ä¿æŒé™æ€ï¼Œç”¨æˆ·è¾“å…¥ä½œä¸º user message ä¼ å…¥ï¼Œæ•ˆæœæ›´ä½³
    
    ipa_result = get_completion(ipa_prompt, f"Input: {input_text}")
    # æœ‰æ—¶å€™æ¨¡å‹ä¼šé‡å¤ "Output: " å‰ç¼€ï¼Œè¿™é‡Œåšä¸€ä¸ªç®€å•çš„æ¸…æ´—
    ipa_result = ipa_result.replace("Output:", "").strip()

    # ==========================================
    # æ­¥éª¤ 2: è·å–é‡Šä¹‰ (Definitions)
    # ==========================================
    def_prompt = """
You are an expert English Dictionary assistant.
Your task is to provide clear, numbered English definitions for the input.

**Rules:**
1.  **Analyze Input Type:**
    * **Single Word:** Provide the most common, high-frequency meanings.
    * **Phrase / Idiom:** If the input is a phrase (e.g., "look after", "piece of cake"), define the **idiomatic meaning of the whole phrase**, NOT the individual words.

2.  **Frequency Judgement:**
    * If a word/phrase has only **one** common meaning (e.g., "kangaroo"), output **ONLY** that one definition.
    * If a word has **multiple** common meanings (e.g., "bank", "tear"), provide 2-3 definitions.

3.  **Handling Context (Parentheses) - PRIORITY RULE:**
    * If parentheses are present (e.g., "tear (crying)"), they determine the **ORDER**, not the exclusion.
    * **Definition 1** MUST be the specific meaning described in the parentheses.
    * **Definition 2, 3...** MUST list other high-frequency meanings of the word, **even if they have different pronunciations (heteronyms)**. Do not omit other common meanings.

4.  **Format:** Always use a numbered list (1., 2....).

**Examples:**

Input: kangaroo
Output:
1. A large Australian animal with a strong tail and back legs, which moves by jumping.

Input: give up
Output:
1. To stop doing or having something (often a habit).
2. To stop trying to guess or solve something.

Input: once in a blue moon
Output:
1. Very rarely.

Input: bank
Output:
1. An organization where people and businesses can invest or borrow money.
2. The land alongside or sloping down to a river or lake.

Input: date (fruit)
Output:
1. A sweet, dark brown oval fruit containing a hard stone.
2. A particular day of the month or year.
3. A romantic meeting or social engagement.

Input: tear (crying)
Output:
1. A drop of clear salty liquid secreted by glands in your eyes.
2. To pull or rip something apart or to pieces with force.
"""
    definitions_result = get_completion(def_prompt, f"Input: {input_text}")
    definitions_result = definitions_result.replace("Output:", "").strip()

    # ==========================================
    # æ­¥éª¤ 3: è·å–ä¾‹å¥ (Examples)
    # ==========================================
    # è¿™ä¸€æ­¥ä¾èµ–äºã€æ¸…æ´—åçš„å•è¯ã€‘å’Œã€ä¸Šä¸€æ­¥ç”Ÿæˆçš„é‡Šä¹‰ã€‘
    
    ex_prompt = """
You are an English teacher.
Your task is to write example sentences corresponding to a provided list of numbered definitions.

**Rules:**
1.  **Input:** You will receive a target Word/Phrase and a Numbered List of Definitions.
2.  **Output Format:** Provide a numbered list of example sentences that strictly matches the order and quantity of the provided definitions.
3.  **Content:**
    * The sentence must clearly illustrate the specific meaning of that definition.
    * **Phrases:** If the input is a phrase, the sentence must include the phrase naturally.
    * Keep the sentences natural and suitable for an English learner.

**Examples:**

Input Word: kangaroo
Input Definitions:
1. A large Australian animal with a strong tail and back legs, which moves by jumping.

Output:
1. We saw a kangaroo jumping across the field during our trip to Australia.

Input Word: give up
Input Definitions:
1. To stop doing or having something (often a habit).
2. To stop trying to guess or solve something.

Output:
1. I decided to give up smoking last year for my health.
2. I give up; tell me the answer to the riddle.

Input Word: bank
Input Definitions:
1. An organization where people and businesses can invest or borrow money.
2. The land alongside or sloping down to a river or lake.

Output:
1. I need to stop by the bank to withdraw some cash.
2. They sat on the river bank and fished all afternoon.
"""
    
    # æ„å»º Step 3 çš„ç”¨æˆ·è¾“å…¥
    step3_user_input = f"""**Current Input Word:**
{cleaned_word}

**Current Input Definitions:**
{definitions_result}"""

    examples_result = get_completion(ex_prompt, step3_user_input)
    examples_result = examples_result.replace("Output:", "").strip()

    # ==========================================
    # æ„é€ è¿”å›å€¼
    # ==========================================
    return {
        "word": cleaned_word,
        "ipa": ipa_result,
        "definitions": definitions_result,
        "examples": examples_result
    }



def generate_audio_files(word_card: dict, output_dir="media", speed_config=None, azure_config=None) -> dict:
    """
    æ¥æ”¶ generate_word_card çš„è¿”å›ç»“æœï¼Œåˆ©ç”¨ Azure TTS ç”Ÿæˆ 4 ä¸ªéŸ³é¢‘æ–‡ä»¶ã€‚
    
    Args:
        word_card (dict): åŒ…å« word, definitions, examples çš„å­—å…¸
        output_dir (str): éŸ³é¢‘æ–‡ä»¶çš„ä¿å­˜ç›®å½•ï¼Œé»˜è®¤ä¸º "media"
        speed_config (dict, optional): è‡ªå®šä¹‰è¯­é€Ÿé…ç½®ã€‚
            é»˜è®¤å€¼å¦‚ä¸‹ï¼Œä½ å¯ä»¥ä¼ å…¥å­—å…¸è¦†ç›–ç‰¹å®šé¡¹ï¼š
            {
                "word_slow": "-30%",   # å•è¯æ…¢è¯» (å‡æ…¢30%)
                "word_fast": "0%",     # å•è¯å¿«è¯» (åŸé€Ÿ)
                "definitions": "0%",   # é‡Šä¹‰ (åŸé€Ÿ)
                "examples": "-5%"      # ä¾‹å¥ (ç¨æ…¢)
            }
        azure_config (dict, optional): Azure TTS é…ç½®ï¼ŒåŒ…å« speech_key, region, voice_name
        
    Returns:
        dict: åœ¨åŸå­—å…¸åŸºç¡€ä¸Šå¢åŠ äº† audio_files å­—æ®µï¼ŒåŒ…å«å…·ä½“çš„æ–‡ä»¶è·¯å¾„
    """
    
    # ==========================================
    # 0. å¤„ç†è¯­é€Ÿé…ç½® (é»˜è®¤å€¼ + ç”¨æˆ·è¦†ç›–)
    # ==========================================
    # Azure rate æ”¯æŒæ ¼å¼: "-30%"(å‡æ…¢), "+20%"(åŠ å¿«), "0%"(åŸé€Ÿ)
    current_speeds = {
        "word_slow": "-30%",
        "word_fast": "0%",
        "definitions": "-10%",
        "examples": "-10%"
    }
    # å¦‚æœç”¨æˆ·ä¼ äº†é…ç½®ï¼Œåˆ™æ›´æ–°é»˜è®¤å€¼
    if speed_config:
        current_speeds.update(speed_config)

    # 1. æ£€æŸ¥ API Key (ä½¿ç”¨é…ç½®æˆ–é»˜è®¤å€¼)
    if azure_config is None:
        azure_config = {
            "speech_key": "è¯·åœ¨ config.yaml ä¸­é…ç½®ä½ çš„ Azure è¯­éŸ³æœåŠ¡è®¢é˜…å¯†é’¥",
            "region": "eastus",
            "voice_name": "en-GB-SoniaNeural"
        }
    
    speech_key = azure_config.get("speech_key", "")
    service_region = azure_config.get("region", "eastus") 

    if not speech_key or not service_region:
        raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ AZURE_SPEECH_KEY å’Œ AZURE_SPEECH_REGION")

    # 2. ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # 3. åˆå§‹åŒ– Azure åˆæˆå™¨
    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
    voice_name = azure_config.get("voice_name", "en-GB-SoniaNeural")
    speech_config.speech_synthesis_voice_name = voice_name

    # 4. å®šä¹‰è¾…åŠ©å‡½æ•°ï¼šæ‰§è¡Œåˆæˆå¹¶ä¿å­˜æ–‡ä»¶
    def synthesize_ssml_to_file(ssml_text, filename):
        file_path = os.path.join(output_dir, filename)
        audio_config = speechsdk.audio.AudioOutputConfig(filename=file_path)
        synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)
        
        result = synthesizer.speak_ssml_async(ssml_text).get()
        
        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            print(f"âœ… ç”ŸæˆæˆåŠŸ: {filename}")
            return file_path
        elif result.reason == speechsdk.ResultReason.Canceled:
            cancellation_details = result.cancellation_details
            print(f"âŒ ç”Ÿæˆå–æ¶ˆ: {filename}, åŸå› : {cancellation_details.reason}")
            if cancellation_details.reason == speechsdk.CancellationReason.Error:
                print(f"é”™è¯¯è¯¦æƒ…: {cancellation_details.error_details}")
            return None

    # 5. å®šä¹‰è¾…åŠ©å‡½æ•°ï¼šæ„å»º SSML æ¡†æ¶
    def build_ssml(content):
        return f"""
        <speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="en-GB">
            <voice name="{voice_name}">
                {content}
            </voice>
        </speak>
        """

    # --- å‡†å¤‡æ–‡ä»¶å (å»é™¤ç‰¹æ®Šå­—ç¬¦) ---
    clean_word = re.sub(r'[\\/*?:"<>|]', "", word_card['word']).replace(" ", "_")
    paths = {}

    print(f"æ­£åœ¨ä¸ºå•è¯ '{word_card['word']}' ç”ŸæˆéŸ³é¢‘...")

    # ==========================================
    # A. å•è¯æ…¢é€Ÿ (Word Slow)
    # ==========================================
    ssml_slow = build_ssml(f"""
        <prosody rate="{current_speeds['word_slow']}">
            {word_card['word']}
        </prosody>
    """)
    paths['word_slow'] = synthesize_ssml_to_file(ssml_slow, f"{clean_word}_slow.mp3")

    # ==========================================
    # B. å•è¯å¿«é€Ÿ/æ­£å¸¸ (Word Fast)
    # ==========================================
    ssml_fast = build_ssml(f"""
        <prosody rate="{current_speeds['word_fast']}">
            {word_card['word']}
        </prosody>
    """)
    paths['word_fast'] = synthesize_ssml_to_file(ssml_fast, f"{clean_word}_fast.mp3")

    # ==========================================
    # C. é‡Šä¹‰æœ—è¯» (Definitions)
    # ==========================================
    def_lines = word_card['definitions'].split('\n')
    def_lines = [line.strip() for line in def_lines if line.strip()]
    
    def_content = ""
    for line in def_lines:
        # è¿™é‡Œç»™æ¯ä¸€è¡Œéƒ½åŠ ä¸Šäº†è¯­é€Ÿæ§åˆ¶
        def_content += f"<prosody rate='{current_speeds['definitions']}'>{line}</prosody> <break time='800ms'/> "
    
    ssml_defs = build_ssml(def_content)
    paths['definitions'] = synthesize_ssml_to_file(ssml_defs, f"{clean_word}_defs.mp3")

    # ==========================================
    # D. ä¾‹å¥æœ—è¯» (Examples)
    # ==========================================
    ex_lines = word_card['examples'].split('\n')
    ex_lines = [line.strip() for line in ex_lines if line.strip()]

    ex_content = ""
    for line in ex_lines:
        ex_content += f"<prosody rate='{current_speeds['examples']}'>{line}</prosody> <break time='1000ms'/> "

    ssml_examples = build_ssml(ex_content)
    paths['examples'] = synthesize_ssml_to_file(ssml_examples, f"{clean_word}_ex.mp3")

    return paths


def create_anki_package(word_list: list, package_name="My_Vocabulary_Deck.apkg", media_output_dir="media_temp", 
                       api_config=None, azure_config=None, speed_config=None, deck_name="new words deck"):
    """
    è¾“å…¥ä¸€ä¸ªå•è¯åˆ—è¡¨ï¼Œè‡ªåŠ¨å®Œæˆï¼šå†…å®¹ç”Ÿæˆ -> è¯­éŸ³åˆæˆ -> åˆ¶å¡ -> æ‰“åŒ… (.apkg)
    
    Args:
        word_list: å•è¯åˆ—è¡¨
        package_name: è¾“å‡ºçš„ apkg æ–‡ä»¶å
        media_output_dir: ä¸´æ—¶åª’ä½“æ–‡ä»¶ç›®å½•
        api_config: OpenAI API é…ç½®
        azure_config: Azure TTS é…ç½®
        speed_config: è¯­é€Ÿé…ç½®
        deck_name: Anki å¡ç»„åç§°
    """

    # =========================================================
    # 1. å®šä¹‰ Anki æ¨¡æ¿ (Modern Typography Style - æœ€ç»ˆå®Œç¾ç‰ˆ)
    # =========================================================
    
    modern_css = """
    .card { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; font-size: 16px; line-height: 1.6; color: #333; background-color: #f4f4f7; display: flex; justify-content: center; align-items: flex-start; height: 100%; margin: 0; padding: 20px; }
    .main-container { background-color: #fff; width: 100%; max-width: 600px; border-radius: 16px; box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08); padding: 30px; text-align: left; box-sizing: border-box; }
    .word-header { text-align: center; margin-bottom: 10px; }
    .word { font-size: 2.8rem; font-weight: 700; color: #2d3436; letter-spacing: -0.5px; margin-bottom: 5px; }
    .ipa { font-family: "Menlo", "Monaco", "Consolas", monospace; font-size: 1.1rem; color: #888; background-color: #f0f0f0; padding: 2px 8px; border-radius: 6px; display: inline-block; }
    .audio-bar { text-align: center; margin-top: 15px; margin-bottom: 25px; }
    hr.divider { border: 0; height: 1px; background: #eee; margin: 20px 0; }
    .section-title { font-size: 0.8rem; text-transform: uppercase; letter-spacing: 1px; font-weight: 600; color: #b2bec3; margin-bottom: 10px; display: flex; align-items: center; gap: 8px; }
    
    /* ã€ä¿®å¤ç‚¹ 1ã€‘white-space æ”¹ä¸º pre-line
       pre-wrap ä¼šæŠŠä»£ç é‡Œçš„ç¼©è¿›ä¹Ÿæ˜¾ç¤ºå‡ºæ¥ï¼Œå¯¼è‡´å‰é¢ç©ºä¸¤æ ¼ã€‚
       pre-line ä¼šåˆå¹¶ç©ºç™½ï¼Œä½†ä¿ç•™æ¢è¡Œç¬¦ï¼Œå®Œç¾è§£å†³é—®é¢˜ã€‚
    */
    .content-box { padding: 12px 10px; border-radius: 8px; margin-bottom: 20px; white-space: pre-line; }

    /* ã€ä¿®å¤ç‚¹ 2ã€‘å­—å·å·²æ”¾å¤§ 1.3 å€ */
    .definition-box { background-color: #fbfbfb; border-left: 4px solid #0984e3; font-size: 1.45rem; color: #2d3436; }
    .example-box { background-color: #fbfbfb; border-left: 4px solid #00b894; font-size: 1.3rem; color: #555; font-style: italic; }
    
    .audio-tag { font-size: 0.8rem; color: #aaa; margin-top: 8px; text-align: right; display: flex; justify-content: flex-end; align-items: center; gap: 5px; }
    
    /* å¤œé—´æ¨¡å¼ */
    .nightMode .card { background-color: #1e1e1e; color: #f5f6fa; }
    .nightMode .main-container { background-color: #2d2d2d; box-shadow: 0 4px 12px rgba(0, 0, 0, 0.4); }
    .nightMode .word { color: #f5f6fa; }
    .nightMode .ipa { background-color: #383838; color: #bbb; }
    .nightMode hr.divider { background: #444; }
    .nightMode .definition-box { background-color: #333; border-left-color: #74b9ff; color: #eee; }
    .nightMode .example-box { background-color: #333; border-left-color: #55efc4; color: #ccc; }
    """

    # æ­£é¢ HTML (ä¿æŒä»£ç æ•´æ´)
    front_html = """
    <div class="main-container">
        <div class="word-header">
            <div class="word">{{Word}}</div>
            <div class="ipa">{{IPA}}</div>
        </div>
        <div class="audio-bar">{{WordAudio}}</div>
    </div>
    """

    # èƒŒé¢ HTML
    # ã€ä¿®å¤ç‚¹ 3ã€‘è¿™é‡Œæˆ‘æŠŠ {{Definitions}} ç´§ç´§è´´åœ¨ class="..." åé¢ï¼Œç‰©ç†ä¸Šæ¶ˆé™¤ç©ºæ ¼
    back_html = """
    <div class="main-container">
        <div class="word-header">
            <div class="word">{{Word}}</div>
            <div class="ipa">{{IPA}}</div>
        </div>
        <div class="audio-bar">{{WordAudio}}</div>
        <hr class="divider">
        <div class="section-title"><span>ğŸ“– Definitions</span></div>
        <div class="content-box definition-box">{{Definitions}}<div class="audio-tag"><span>Listen</span> {{MeaningAudio}}</div></div>
        <div class="section-title"><span>ğŸ—£ï¸ Examples</span></div>
        <div class="content-box example-box">{{Examples}}<div class="audio-tag"><span>Listen</span> {{ExampleAudio}}</div></div>
    </div>
    """

    # å®šä¹‰ Model (å›ºå®šID)
    model_id = 1683920450
    
    my_model = genanki.Model(
        model_id,
        'Modern Auto Vocab',
        fields=[
            {'name': 'Word'},
            {'name': 'IPA'},
            {'name': 'WordAudio'},
            {'name': 'Definitions'},
            {'name': 'Examples'},
            {'name': 'MeaningAudio'},
            {'name': 'ExampleAudio'},
        ],
        templates=[
            {
                'name': 'Card 1',
                'qfmt': front_html,
                'afmt': back_html,
            },
        ],
        css=modern_css
    )

    # =========================================================
    # 2. åˆ›å»º Deck
    # =========================================================
    deck_id = 2059400110
    my_deck = genanki.Deck(deck_id, deck_name)

    all_media_files = []

    # =========================================================
    # 3. æ‰¹é‡å¤„ç†
    # =========================================================
    print(f"ğŸš€ å¼€å§‹åˆ¶ä½œå¡ç»„ï¼Œå…± {len(word_list)} ä¸ªå•è¯...")
    
    for i, word_input in enumerate(word_list, 1):
        print(f"\n[{i}/{len(word_list)}] æ­£åœ¨å¤„ç†: {word_input}")
        
        try:
            # Step A: LLM ç”Ÿæˆ
            text_data = generate_word_card(word_input, api_config=api_config)
            
            # Step B: TTS ç”Ÿæˆ
            audio_paths = generate_audio_files(text_data, output_dir=media_output_dir, 
                                             speed_config=speed_config, azure_config=azure_config)
            
            if not audio_paths:
                print("   âš ï¸ éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡ã€‚")
                continue

            # Step C: å‡†å¤‡æ•°æ®
            def get_sound_tag(key):
                path = audio_paths.get(key)
                if path and os.path.exists(path):
                    all_media_files.append(path)
                    return f"[sound:{os.path.basename(path)}]"
                return ""

            # æ‹¼æ¥å•è¯éŸ³é¢‘ (å…ˆæ…¢åå¿«)
            combined_word_audio = get_sound_tag('word_slow') + " " + get_sound_tag('word_fast')

            # å¡«å……å­—æ®µ (ä½¿ç”¨ strip å»é™¤æ•°æ®æœ¬èº«çš„ç©ºæ ¼)
            note = genanki.Note(
                model=my_model,
                fields=[
                    text_data['word'],
                    text_data['ipa'],
                    combined_word_audio,
                    text_data['definitions'].strip(),
                    text_data['examples'].strip(),
                    get_sound_tag('definitions'),
                    get_sound_tag('examples')
                ]
            )
            
            my_deck.add_note(note)
            print(f"   âœ… æ·»åŠ æˆåŠŸ: {text_data['word']}")

        except Exception as e:
            print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    # =========================================================
    # 4. æ‰“åŒ…
    # =========================================================
    if len(my_deck.notes) == 0:
        print("\nâŒ æ— å¡ç‰‡ç”Ÿæˆã€‚")
        return

    print(f"\nğŸ“¦ æ­£åœ¨æ‰“åŒ… {len(all_media_files)} ä¸ªåª’ä½“æ–‡ä»¶...")
    
    my_package = genanki.Package(my_deck)
    my_package.media_files = all_media_files
    
    my_package.write_to_file(package_name)
    print(f"ğŸ‰ ç”Ÿæˆå®Œæ¯•: {os.path.abspath(package_name)}")
    print("ğŸ‘‰ è¯·åŒå‡»è¯¥æ–‡ä»¶å¯¼å…¥ Ankiï¼")

# ==========================================
# è°ƒç”¨ç¤ºä¾‹
# ==========================================
# ==============================================================================
# è”åŠ¨æµ‹è¯•ä»£ç 
# å‡è®¾ä½ çš„ä¸¤ä¸ªå‡½æ•° generate_word_card å’Œ generate_audio_files éƒ½åœ¨å½“å‰è„šæœ¬ä¸­å®šä¹‰å¥½äº†
# ==============================================================================

if __name__ == "__main__":
    # 1. å‡†å¤‡æµ‹è¯•åˆ—è¡¨ï¼šè¦†ç›–å¤šä¹‰è¯ã€çŸ­è¯­ã€å•ä¹‰è¯ç­‰ä¸åŒæƒ…å†µ
    test_inputs = [
        "tear (crying)",        # æµ‹è¯•è¯­å¢ƒä¼˜å…ˆ + å¤šéŸ³å¤šä¹‰è¯ (Heteronym)
        "hold on",              # æµ‹è¯•åŠ¨è¯çŸ­è¯­ (Phrasal Verb)
        "content (happy)",      # æµ‹è¯•å¦ä¸€ä¸ªå¤šéŸ³å¤šä¹‰è¯
        "kangaroo"              # æµ‹è¯•å•ä¹‰è¯
    ]

    # 2. å®šä¹‰ä½ å–œæ¬¢çš„è¯­é€Ÿé…ç½®
    my_speed_settings = {
        "word_slow": "-35%",    # å•è¯è¯»å¾—å†æ…¢ä¸€ç‚¹
        "word_fast": "0%",      # å•è¯å¸¸é€Ÿ
        "definitions": "0%",    # é‡Šä¹‰å¸¸é€Ÿ
        "examples": "-10%"      # ä¾‹å¥ç¨å¾®æ…¢ä¸€ç‚¹ç‚¹ï¼Œæ–¹ä¾¿å¬æ¸…ç»“æ„
    }

    # 3. æŒ‡å®šè¾“å‡ºæ–‡ä»¶å¤¹
    media_dir = "anki_media_output"

    print(f"ğŸš€ å¼€å§‹æ‰¹é‡åˆ¶å¡ä»»åŠ¡ï¼Œå…± {len(test_inputs)} ä¸ªç›®æ ‡...\n")
    print("-" * 60)

    for i, input_text in enumerate(test_inputs, 1):
        print(f"ğŸ“ [{i}/{len(test_inputs)}] æ­£åœ¨å¤„ç†è¾“å…¥: '{input_text}'")

        try:
            # -------------------------------------------
            # ç¬¬ä¸€æ­¥ï¼šè°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæ–‡æœ¬å†…å®¹ (LLM)
            # -------------------------------------------
            print("   [Step 1] æ­£åœ¨è¯·æ±‚ AI ç”Ÿæˆæ–‡æœ¬å†…å®¹...")
            card_data = generate_word_card(input_text)
            
            # ç®€å•å±•ç¤ºä¸€ä¸‹ç”Ÿæˆäº†ä»€ä¹ˆ
            print(f"      -> å•è¯: {card_data['word']}")
            print(f"      -> éŸ³æ ‡: {card_data['ipa']}")
            print(f"      -> é‡Šä¹‰è¡Œæ•°: {len(card_data['definitions'].splitlines())}")

            # -------------------------------------------
            # ç¬¬äºŒæ­¥ï¼šè°ƒç”¨ Azure ç”Ÿæˆè¯­éŸ³æ–‡ä»¶ (TTS)
            # -------------------------------------------
            print("   [Step 2] æ­£åœ¨è¯·æ±‚ Azure ç”Ÿæˆè¯­éŸ³ (åº”ç”¨è‡ªå®šä¹‰è¯­é€Ÿ)...")
            audio_paths = generate_audio_files(
                word_card=card_data,
                output_dir=media_dir,
                speed_config=my_speed_settings
            )

            # -------------------------------------------
            # ç¬¬ä¸‰æ­¥ï¼šç»“æœæ±‡æ€»
            # -------------------------------------------
            print("   âœ… å¤„ç†æˆåŠŸï¼ç”Ÿæˆç´ æå¦‚ä¸‹:")
            if audio_paths:
                print(f"      ğŸµ æ…¢é€Ÿå•è¯: {audio_paths.get('word_slow')}")
                print(f"      ğŸµ å¿«é€Ÿå•è¯: {audio_paths.get('word_fast')}")
                print(f"      ğŸµ é‡Šä¹‰æœ—è¯»: {audio_paths.get('definitions')}")
                print(f"      ğŸµ ä¾‹å¥æœ—è¯»: {audio_paths.get('examples')}")
            else:
                print("      âš ï¸ æœªç”ŸæˆéŸ³é¢‘ (å¯èƒ½ Key é”™è¯¯æˆ–é¢åº¦ä¸è¶³)")

        except Exception as e:
            print(f"   âŒ å½“å‰æ¡ç›®å¤„ç†å¤±è´¥: {e}")
            # è¿™é‡Œæ‰“å°è¯¦ç»†é”™è¯¯å †æ ˆï¼Œæ–¹ä¾¿ä½ æ’æŸ¥æ˜¯ LLM æŒ‚äº†è¿˜æ˜¯ Azure æŒ‚äº†
            import traceback
            traceback.print_exc()

        print("-" * 60)

    print(f"\nğŸ‰ æ‰€æœ‰ä»»åŠ¡ç»“æŸã€‚è¯·æ£€æŸ¥æ–‡ä»¶å¤¹: {os.path.abspath(media_dir)}")